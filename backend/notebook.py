# -*- coding: utf-8 -*-
"""final_cyber.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-pYtVGlb-kDWWmjTQ8PfRerQD4N77-x3

Cyber Threat Detection

- This project focuses on detecting cyber threats using machine learning techniques. 
 By analyzing network traffic data, the model aims to identify and classify different types of cyber-attacks such as DDoS, Ransomware, and Normal traffic. 
 The dataset contains various network attributes such as packet length, protocol type, and traffic flow metrics to help the model distinguish between normal and malicious activities.

*   Data Cleaning and Preprocessing
*   Exploratory Data Analysis
*   Model Selection
*   Hyper Parameter Tuning
"""

# Import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score,confusion_matrix,ConfusionMatrixDisplay,roc_auc_score
from sklearn.naive_bayes import GaussianNB

# Load the dataset
cyber_data = pd.read_csv('cyberfeddefender_dataset.csv')

#Fetching first few rows from DataFrame
cyber_data.head()

# Replacing all column names with smaller case and replace " " with "_" in column names
cyber_data.columns = cyber_data.columns.str.lower().str.replace(' ', '_')

#Fetching first few rows from DataFrame
cyber_data.head()

# Check for missing values
print(cyber_data.isnull().sum())

print(cyber_data.dtypes)

#To check for no of unique values of 'flow_bytes/s'
print(cyber_data['flow_bytes/s'].nunique)

# Impute missing values (if any) with median for numerical features - In this case - flow_bytes/s
imputer = SimpleImputer(strategy='median')
cyber_data[['flow_bytes/s']] = imputer.fit_transform(cyber_data[['flow_bytes/s']])

"""Exploratory Data Analysis"""

# Checking the distribution of 'flow_bytes/s'
import matplotlib.pyplot as plt
cyber_data['flow_bytes/s'].hist(bins=30, edgecolor='black')
plt.title('Histogram')
plt.xlabel('Values')
plt.ylabel('Frequency')
plt.show()

#Log1p Transformation of 'flow_bytes/s'
cyber_data['transformed_flow_bytes/s'] = np.log1p(cyber_data['flow_bytes/s'])

cyber_data['transformed_flow_bytes/s'].hist(bins=30, edgecolor='black')
plt.title('Histogram')
plt.xlabel('Values')
plt.ylabel('Frequency')
plt.show()

#Removing insignificant columns after testing the model as the below columns had no impact on Label
insignificant_columns = ['timestamp','source_ip','destination_ip','flow_bytes/s','transformed_flow_bytes/s']
cyber_data.copy = cyber_data.copy()
cyber_data.drop(insignificant_columns, axis=1, inplace=True)

#Label encoding of categorical data
encode_cols = ['protocol','flags','attack_type']
label_encoder = LabelEncoder()
# Fit and transform the categorical labels
for col in encode_cols:
    cyber_data[col] = label_encoder.fit_transform(cyber_data[col])

cyber_data.head()

# Standardization of continuous features
continuous_features = [
    'packet_length', 'source_port','destination_port', 'bytes_sent', 'bytes_received',
    'flow_packets/s', 'avg_packet_size', 'total_fwd_packets','total_bwd_packets',
    'fwd_header_length','bwd_header_length','sub_flow_fwd_bytes','sub_flow_bwd_bytes'
]


scaler = StandardScaler()
cyber_data[continuous_features] = scaler.fit_transform(cyber_data[continuous_features])

print(cyber_data.head())

print(cyber_data.describe())

# Multiple features box plot
sns.boxplot(data=cyber_data)
plt.title("Box Plot - Multiple Features")
plt.xticks(rotation=45)  # Rotate feature names if needed
plt.show()

#Setting Feature and Target Variables to train the model
X = cyber_data.drop(columns=['label'])
y = cyber_data['label']

# Fit a RandomForest model to get feature_importances_
rf = RandomForestClassifier(random_state=42)
rf.fit(X, y)

# Get feature importance
feature_importances = pd.DataFrame({
    "Feature": X.columns,
    "Importance": rf.feature_importances_
}).sort_values(by="Importance", ascending=False)

print(feature_importances)

#Dropping least important columns based on feature_importances
cols_to_drop = ["inbound", "protocol", "bwd_header_length", "fwd_header_length", "flags", "avg_packet_size"]
cyber_data = cyber_data.drop(columns=cols_to_drop)

cyber_data.head()

cyber_data['attack_type'].nunique

cyber_data.head()

cyber_data.head().T

cyber_data.columns

#Finalized feature and target variable
X = cyber_data.drop(columns=['label'])
y = cyber_data['label']

print(X.isnull().sum())

"""Splitting the data into Training and Test Data"""

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Evaluating different Classification models"""

# Create a dictionary of models
models = {
    'Logistic Regression': LogisticRegression(random_state=42),
    'Decision Tree Classifier' : DecisionTreeClassifier(random_state=42),
    'Random Forest Classifier': RandomForestClassifier(random_state=42),
    'Support Vector Classifier': SVC(kernel='poly', C = 10, degree = 3, gamma = 'auto', probability=True, class_weight='balanced',random_state=42),
    'Naive Bayes Classifier': GaussianNB()
}

# Function to evaluate models
def evaluate_models(models, X_train, X_test, y_train, y_test):
    results = {}
    print(models.items())
    for name, model in models.items():
        print("****",name,"****")
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        #Calculate Accuracy Score
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred)
        # Generate confusion matrix
        cm = confusion_matrix(y_test, y_pred)
         # Plot the confusion matrix
        cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])
        cm_disp.plot(cmap='Blues')
        print(name,": Confusion Matrix")
        print("\n")
        results[name] = {'accuracy': accuracy, 'classification_report': report}
    return results

# Evaluate all models
results = evaluate_models(models, X_train, X_test, y_train, y_test)

# Display the results
for model_name, metrics in results.items():
    print(f"Model: {model_name}")
    print(f"Accuracy: {metrics['accuracy']}")
    print(f"Classification Report: \n{metrics['classification_report']}")

"""Hyperparameter Tuning Using XGBClassifier

(But SVC shows more accuracy than XGBClassifier)
"""

from xgboost import XGBClassifier

# Initialize XGBoost Classifier
xgb_model = XGBClassifier(
    random_state=42,
    n_estimators=300,        # Number of trees
    learning_rate=0.05,      # Learning rate (step size shrinkage)
    max_depth=6,             # Maximum depth of a tree
    colsample_bytree=0.8,    # Fraction of features used per tree
    subsample=0.8,           # Fraction of samples used per tree
    eval_metric='logloss'    # Evaluation metric
)

# Fit the model
xgb_model.fit(X_train, y_train)

# Predict on the test set
y_pred = xgb_model.predict(X_test)

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"XGBoost Accuracy: {accuracy:.4f}")

# Display a detailed classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

#Grid Params - Best params for tuning SVC model - Commented after running once
'''from sklearn.model_selection import GridSearchCV
param_grid = {
    'C': [0.1, 1, 10],
    'kernel': ['poly', 'rbf', 'sigmoid'],
    'degree': [2, 3, 4],
    'gamma': ['scale', 'auto']
}
grid = GridSearchCV(SVC(), param_grid, scoring='f1_weighted', cv=5)
grid.fit(X_train, y_train)
print(grid.best_params_)'''

"""AUC ROC Curve"""

from sklearn.metrics import roc_curve, auc, RocCurveDisplay
#Train SVC with probability=True
svc = SVC(kernel='poly', probability=True, random_state=42)
svc.fit(X_train, y_train)

#Predict probabilities
y_prob = svc.predict_proba(X_test)[:, 1]  # Get probability for the positive class

#Calculate ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

#Plot ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

"""BaggingClassifier - Tested for Max Accuracy but still SVC shares more accuracy and hence chose SVC as finalized model"""

from sklearn.ensemble import BaggingClassifier
bagging_svc = BaggingClassifier(estimator=SVC(kernel='poly', C = 10, degree = 3, gamma = 'auto', probability=True, class_weight='balanced'), n_estimators=10, random_state=42)
bagging_svc.fit(X_train, y_train)
y_pred = bagging_svc.predict(X_test)

# Evaluate the model
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# AUC-ROC score
y_prob = bagging_svc.predict_proba(X_test)[:, 1]  # For AUC
auc = roc_auc_score(y_test, y_prob)
print("AUC-ROC:", auc)